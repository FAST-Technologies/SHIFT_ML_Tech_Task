{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74a02a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_preprocessing_improved_fixed(\n",
    "    train_df: pd.DataFrame, \n",
    "    test_df: pd.DataFrame, \n",
    "    target_col: str = 'итоговый_статус_займа',\n",
    "    RANDOM_STATE: int = 42\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Улучшенная предобработка данных с сохранением всех параметров\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"НАЧАЛО ПРЕДОБРАБОТКИ (С СОХРАНЕНИЕМ ПАРАМЕТРОВ)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Сохраняем параметры для воспроизводимости\n",
    "    params = {\n",
    "        'rating_order': {'А': 1, 'Б': 2, 'В': 3, 'Г': 4, 'Д': 5, 'Е': 6, 'Ж': 7},\n",
    "        'experience_order': {\n",
    "            '< 1 года': 0.5, '1 год': 1, '2 года': 2, '3 года': 3, \n",
    "            '4 года': 4, '5 лет': 5, '6 лет': 6, '7 лет': 7, \n",
    "            '8 лет': 8, '9 лет': 9, '10+ лет': 10\n",
    "        },\n",
    "        'binary_mapping': {'Да': 1, 'Нет': 0, 'Под вопросом': 0.5, 'True': 1, 'False': 0},\n",
    "        'useless_cols': [\n",
    "            'дата_следующей_выплаты',\n",
    "            'кредитный_баланс_по_возоб_счетам',\n",
    "            'совокупный_статус_подтверждения_доходов_заемщиков',\n",
    "            'совокупный_пдн_заемщиков',\n",
    "            'совокупный_доход_заемщиков',\n",
    "        ],\n",
    "        'constant_cols': ['платежный_график', 'особая_ситуация'],\n",
    "        'binary_cols': ['пос_стоп_фактор', 'юридический_статус'],\n",
    "        'onehot_cols': [\n",
    "            'владение_жильем', 'подтвержден_ли_доход',\n",
    "            'первоначальный_статус_займа', 'тип_займа',\n",
    "            'тип_предоставления_кредита'\n",
    "        ],\n",
    "        'freq_cols': ['профессия_заемщика', 'допрейтинг', 'регион']\n",
    "    }\n",
    "    \n",
    "    # Копируем данные\n",
    "    train_df_processed = train_df.copy()\n",
    "    test_df_processed = test_df.copy()\n",
    "    \n",
    "    # Сохраняем ID и target\n",
    "    train_ids = train_df_processed['id'].copy()\n",
    "    test_ids = test_df_processed['id'].copy()\n",
    "    y = train_df_processed[target_col].copy() if target_col in train_df_processed.columns else None\n",
    "    \n",
    "    print(f\"Начальные размеры: train={train_df_processed.shape}, test={test_df_processed.shape}\")\n",
    "    \n",
    "    # 1. УДАЛЕНИЕ БЕСПОЛЕЗНЫХ ПРИЗНАКОВ\n",
    "    print(\"\\n1. Удаление бесполезных признаков...\")\n",
    "    cols_to_drop = [col for col in params['useless_cols'] + params['constant_cols'] \n",
    "                    if col in train_df_processed.columns]\n",
    "    train_df_processed = train_df_processed.drop(columns=cols_to_drop, errors='ignore')\n",
    "    test_df_processed = test_df_processed.drop(columns=cols_to_drop, errors='ignore')\n",
    "    print(f\"✓ Удалено {len(cols_to_drop)} признаков\")\n",
    "    \n",
    "    # 2. ОБРАБОТКА ПРИЗНАКОВ\n",
    "    print(\"\\n2. Обработка признаков...\")\n",
    "    \n",
    "    # 2.1 Обработка дат\n",
    "    if 'дата_первого_займа' in train_df_processed.columns:\n",
    "        for df in [train_df_processed, test_df_processed]:\n",
    "            df['дата_первого_займа'] = pd.to_datetime(df['дата_первого_займа'], format='%m-%Y', errors='coerce')\n",
    "            current_date = pd.Timestamp('2026-01-01')\n",
    "            df['стаж_кредитной_истории_мес'] = ((current_date - df['дата_первого_займа']).dt.days / 30).fillna(0)\n",
    "            df['стаж_кредитной_истории_мес'] = df['стаж_кредитной_истории_мес'].clip(0, 600)\n",
    "            df.drop(columns=['дата_первого_займа'], inplace=True)\n",
    "        print(\"✓ Создан признак: стаж_кредитной_истории_мес\")\n",
    "    \n",
    "    # 2.2 Обработка сроков займа\n",
    "    if 'срок_займа' in train_df_processed.columns:\n",
    "        for df in [train_df_processed, test_df_processed]:\n",
    "            df['срок_займа_мес'] = df['срок_займа'].str.extract(r'(\\d+)').astype(float)\n",
    "            df['срок_займа_мес'] = df['срок_займа_мес'] * 12\n",
    "            df.drop(columns=['срок_займа'], inplace=True)\n",
    "        print(\"✓ Создан признак: срок_займа_мес\")\n",
    "    \n",
    "    # 2.3 Кодирование рейтингов\n",
    "    if 'рейтинг' in train_df_processed.columns:\n",
    "        for df in [train_df_processed, test_df_processed]:\n",
    "            df['рейтинг_encoded'] = df['рейтинг'].map(params['rating_order']).fillna(0)\n",
    "            df.drop(columns=['рейтинг'], inplace=True)\n",
    "        print(\"✓ Закодирован рейтинг\")\n",
    "    \n",
    "    # 2.4 Стаж работы (сохраняем медиану из train)\n",
    "    if 'стаж' in train_df_processed.columns:\n",
    "        # Кодируем train\n",
    "        train_df_processed['стаж_encoded'] = train_df_processed['стаж'].map(params['experience_order'])\n",
    "        median_experience = train_df_processed['стаж_encoded'].median()\n",
    "        train_df_processed['стаж_encoded'] = train_df_processed['стаж_encoded'].fillna(median_experience)\n",
    "        train_df_processed.drop(columns=['стаж'], inplace=True)\n",
    "        \n",
    "        # Кодируем test с той же медианой\n",
    "        test_df_processed['стаж_encoded'] = test_df_processed['стаж'].map(params['experience_order'])\n",
    "        test_df_processed['стаж_encoded'] = test_df_processed['стаж_encoded'].fillna(median_experience)\n",
    "        test_df_processed.drop(columns=['стаж'], inplace=True)\n",
    "        print(\"✓ Закодирован стаж\")\n",
    "    \n",
    "    # 2.5 Бинарные признаки\n",
    "    for col in params['binary_cols']:\n",
    "        if col in train_df_processed.columns:\n",
    "            for df in [train_df_processed, test_df_processed]:\n",
    "                df[col] = df[col].map(params['binary_mapping']).fillna(0)\n",
    "            print(f\"✓ Закодирован {col}\")\n",
    "    \n",
    "    # 2.6 One-Hot Encoding (сохраняем категории из train)\n",
    "    onehot_categories = {}\n",
    "    for col in params['onehot_cols']:\n",
    "        if col in train_df_processed.columns:\n",
    "            # Заполняем пропуски\n",
    "            train_df_processed[col] = train_df_processed[col].fillna('MISSING')\n",
    "            test_df_processed[col] = test_df_processed[col].fillna('MISSING')\n",
    "            \n",
    "            # Сохраняем уникальные категории из train\n",
    "            unique_vals = train_df_processed[col].unique()\n",
    "            onehot_categories[col] = list(unique_vals)\n",
    "            \n",
    "            # Создаем dummy-переменные для train\n",
    "            dummies_train = pd.get_dummies(train_df_processed[col], prefix=col)\n",
    "            \n",
    "            # Создаем dummy-переменные для test\n",
    "            dummies_test = pd.get_dummies(test_df_processed[col], prefix=col)\n",
    "            \n",
    "            # Выравниваем: добавляем отсутствующие в test\n",
    "            for dummy_col in dummies_train.columns:\n",
    "                if dummy_col not in dummies_test.columns:\n",
    "                    dummies_test[dummy_col] = 0\n",
    "            \n",
    "            # Удаляем лишние из test\n",
    "            for dummy_col in dummies_test.columns:\n",
    "                if dummy_col not in dummies_train.columns:\n",
    "                    dummies_test = dummies_test.drop(columns=[dummy_col])\n",
    "            \n",
    "            # Упорядочиваем как в train\n",
    "            dummies_test = dummies_test[dummies_train.columns]\n",
    "            \n",
    "            # Объединяем\n",
    "            train_df_processed = pd.concat([train_df_processed, dummies_train], axis=1)\n",
    "            test_df_processed = pd.concat([test_df_processed, dummies_test], axis=1)\n",
    "            \n",
    "            # Удаляем исходный признак\n",
    "            train_df_processed.drop(columns=[col], inplace=True)\n",
    "            test_df_processed.drop(columns=[col], inplace=True)\n",
    "            \n",
    "            print(f\"✓ One-hot: {col} ({len(dummies_train.columns)} категорий)\")\n",
    "    \n",
    "    # 2.7 Frequency Encoding (сохраняем частоты из train)\n",
    "    freq_encoders = {}\n",
    "    for col in params['freq_cols']:\n",
    "        if col in train_df_processed.columns:\n",
    "            # Заполняем пропуски\n",
    "            train_df_processed[col] = train_df_processed[col].fillna('MISSING')\n",
    "            test_df_processed[col] = test_df_processed[col].fillna('MISSING')\n",
    "            \n",
    "            # Считаем частоты на train\n",
    "            freq = train_df_processed[col].value_counts(normalize=True)\n",
    "            freq_encoders[col] = freq\n",
    "            \n",
    "            # Применяем к train\n",
    "            train_df_processed[f'{col}_freq_encoded'] = train_df_processed[col].map(freq)\n",
    "            \n",
    "            # Применяем к test\n",
    "            test_df_processed[f'{col}_freq_encoded'] = test_df_processed[col].map(freq)\n",
    "            \n",
    "            # Заполняем пропуски в test средним значением частоты\n",
    "            mean_freq = freq.mean() if len(freq) > 0 else 0\n",
    "            test_df_processed[f'{col}_freq_encoded'] = test_df_processed[f'{col}_freq_encoded'].fillna(mean_freq)\n",
    "            \n",
    "            # Удаляем исходный признак\n",
    "            train_df_processed.drop(columns=[col], inplace=True)\n",
    "            test_df_processed.drop(columns=[col], inplace=True)\n",
    "            \n",
    "            print(f\"✓ Frequency encoding: {col}\")\n",
    "    \n",
    "    # 2.8 Цель займа\n",
    "    if 'цель_займа' in train_df_processed.columns:\n",
    "        purpose_groups = {\n",
    "            'консолидация_долга': ['консолидация_долга'],\n",
    "            'кредитная_карта': ['кредитная_карта'],\n",
    "            'жилье': ['улучшение_жилищных_условий', 'дом'],\n",
    "            'бизнес': ['мелкий_бизнес'],\n",
    "            'авто': ['автомобиль'],\n",
    "            'образование': ['образование'],\n",
    "            'лечение': ['лечение'],\n",
    "            'переезд': ['переезд'],\n",
    "            'отпуск': ['отпуск'],\n",
    "            'другое': ['другое', 'крупная_покупка', 'возобновляемая_энергия', 'свадьба']\n",
    "        }\n",
    "        \n",
    "        purpose_to_group = {}\n",
    "        for group, purposes in purpose_groups.items():\n",
    "            for purpose in purposes:\n",
    "                purpose_to_group[purpose] = group\n",
    "        \n",
    "        # Применяем группировку\n",
    "        for df in [train_df_processed, test_df_processed]:\n",
    "            df['цель_займа'] = df['цель_займа'].fillna('другое')\n",
    "            df['цель_займа_группа'] = df['цель_займа'].map(purpose_to_group)\n",
    "            df.loc[df['цель_займа_группа'].isna(), 'цель_займа_группа'] = 'другое'\n",
    "        \n",
    "        # Сохраняем уникальные группы из train\n",
    "        unique_groups = train_df_processed['цель_займа_группа'].unique()\n",
    "        \n",
    "        # One-hot encoding\n",
    "        dummies_train = pd.get_dummies(train_df_processed['цель_займа_группа'], prefix='цель_займа')\n",
    "        dummies_test = pd.get_dummies(test_df_processed['цель_займа_группа'], prefix='цель_займа')\n",
    "        \n",
    "        # Выравниваем\n",
    "        for dummy_col in dummies_train.columns:\n",
    "            if dummy_col not in dummies_test.columns:\n",
    "                dummies_test[dummy_col] = 0\n",
    "        \n",
    "        for dummy_col in dummies_test.columns:\n",
    "            if dummy_col not in dummies_train.columns:\n",
    "                dummies_test = dummies_test.drop(columns=[dummy_col])\n",
    "        \n",
    "        dummies_test = dummies_test[dummies_train.columns]\n",
    "        \n",
    "        # Объединяем\n",
    "        train_df_processed = pd.concat([train_df_processed, dummies_train], axis=1)\n",
    "        test_df_processed = pd.concat([test_df_processed, dummies_test], axis=1)\n",
    "        \n",
    "        # Удаляем исходные признаки\n",
    "        train_df_processed.drop(columns=['цель_займа', 'цель_займа_группа'], inplace=True)\n",
    "        test_df_processed.drop(columns=['цель_займа', 'цель_займа_группа'], inplace=True)\n",
    "        \n",
    "        print(\"✓ Обработана цель_займа\")\n",
    "    \n",
    "    # 2.9 Обработка пени_за_дефолт (сохраняем медиану)\n",
    "    if 'пени_за_дефолт' in train_df_processed.columns:\n",
    "        for df in [train_df_processed, test_df_processed]:\n",
    "            df['пени_за_дефолт'] = df['пени_за_дефолт'].map({'True': 1, 'False': 0})\n",
    "        \n",
    "        # Вычисляем медиану на train\n",
    "        median_penalty = train_df_processed['пени_за_дефолт'].median()\n",
    "        \n",
    "        # Заполняем пропуски\n",
    "        train_df_processed['пени_за_дефолт'] = train_df_processed['пени_за_дефолт'].fillna(median_penalty)\n",
    "        test_df_processed['пени_за_дефолт'] = test_df_processed['пени_за_дефолт'].fillna(median_penalty)\n",
    "        print(\"✓ Обработано пени_за_дефолт\")\n",
    "    \n",
    "    # 3. СОЗДАНИЕ НОВЫХ ПРИЗНАКОВ\n",
    "    print(\"\\n3. Создание новых признаков...\")\n",
    "    \n",
    "    # 3.1 Финансовые соотношения\n",
    "    if all(col in train_df_processed.columns for col in ['аннуитет', 'годовой_доход']):\n",
    "        for df in [train_df_processed, test_df_processed]:\n",
    "            # Защита от деления на 0\n",
    "            df['годовой_доход_safe'] = df['годовой_доход'].replace(0, 1)\n",
    "            df['аннуитет_к_доходу'] = df['аннуитет'] * 12 / df['годовой_доход_safe']\n",
    "            df.drop(columns=['годовой_доход_safe'], inplace=True)\n",
    "        print(\"✓ Создан: аннуитет_к_доходу\")\n",
    "    \n",
    "    if all(col in train_df_processed.columns for col in ['пдн', 'годовой_доход']):\n",
    "        for df in [train_df_processed, test_df_processed]:\n",
    "            df['годовой_доход_safe'] = df['годовой_доход'].replace(0, 1)\n",
    "            df['пдн_от_дохода'] = df['пдн'] / df['годовой_доход_safe']\n",
    "            df.drop(columns=['годовой_доход_safe'], inplace=True)\n",
    "        print(\"✓ Создан: пдн_от_дохода\")\n",
    "    \n",
    "    if all(col in train_df_processed.columns for col in ['сумма_займа', 'годовой_доход']):\n",
    "        for df in [train_df_processed, test_df_processed]:\n",
    "            df['годовой_доход_safe'] = df['годовой_доход'].replace(0, 1)\n",
    "            df['заем_к_доходу'] = df['сумма_займа'] / df['годовой_доход_safe']\n",
    "            df.drop(columns=['годовой_доход_safe'], inplace=True)\n",
    "        print(\"✓ Создан: заем_к_доходу\")\n",
    "    \n",
    "    # 4. ОБРАБОТКА ПРОПУСКОВ (сохраняем медианы)\n",
    "    print(\"\\n4. Обработка пропусков...\")\n",
    "    \n",
    "    # Собираем медианы из train\n",
    "    medians = {}\n",
    "    numeric_cols_train = train_df_processed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    for col in numeric_cols_train:\n",
    "        if col in train_df_processed.columns and train_df_processed[col].isnull().any() and col != target_col:\n",
    "            medians[col] = train_df_processed[col].median()\n",
    "            train_df_processed[col] = train_df_processed[col].fillna(medians[col])\n",
    "            \n",
    "            # Заполняем test той же медианой\n",
    "            if col in test_df_processed.columns:\n",
    "                test_df_processed[col] = test_df_processed[col].fillna(medians[col])\n",
    "    \n",
    "    print(f\"✓ Заполнены пропуски в {len(medians)} числовых признаках\")\n",
    "    \n",
    "    # 5. УДАЛЕНИЕ ID И ВЫДЕЛЕНИЕ ЦЕЛЕВОЙ ПЕРЕМЕННОЙ\n",
    "    print(\"\\n5. Подготовка финальных наборов данных...\")\n",
    "    \n",
    "    # Выделяем целевую переменную из train\n",
    "    if target_col in train_df_processed.columns:\n",
    "        y = train_df_processed[target_col].copy()\n",
    "        train_df_processed = train_df_processed.drop(columns=[target_col], errors='ignore')\n",
    "    else:\n",
    "        y = None\n",
    "    \n",
    "    # Удаляем ID\n",
    "    X_train = train_df_processed.drop(columns=['id'], errors='ignore')\n",
    "    X_test = test_df_processed.drop(columns=['id'], errors='ignore')\n",
    "    \n",
    "    # 6. УДАЛЕНИЕ КОНСТАНТНЫХ ПРИЗНАКОВ\n",
    "    print(\"\\n6. Удаление константных признаков...\")\n",
    "    constant_cols_final = [col for col in X_train.columns if X_train[col].nunique() == 1]\n",
    "    if constant_cols_final:\n",
    "        X_train = X_train.drop(columns=constant_cols_final, errors='ignore')\n",
    "        X_test = X_test.drop(columns=[col for col in constant_cols_final if col in X_test.columns], errors='ignore')\n",
    "        print(f\"✓ Удалено {len(constant_cols_final)} константных признаков\")\n",
    "    \n",
    "    # 7. ВЫРАВНИВАНИЕ КОЛОНОК\n",
    "    print(\"\\n7. Выравнивание колонок...\")\n",
    "    \n",
    "    # Добавляем отсутствующие колонки в test\n",
    "    missing_in_test = [col for col in X_train.columns if col not in X_test.columns]\n",
    "    if missing_in_test:\n",
    "        for col in missing_in_test:\n",
    "            X_test[col] = 0\n",
    "        print(f\"✓ Добавлено {len(missing_in_test)} отсутствующих колонок в test\")\n",
    "    \n",
    "    # Удаляем лишние колонки из test\n",
    "    extra_in_test = [col for col in X_test.columns if col not in X_train.columns]\n",
    "    if extra_in_test:\n",
    "        X_test = X_test.drop(columns=extra_in_test, errors='ignore')\n",
    "        print(f\"✓ Удалено {len(extra_in_test)} лишних колонок из test\")\n",
    "    \n",
    "    # Упорядочиваем колонки в test как в train\n",
    "    X_test = X_test[X_train.columns]\n",
    "    \n",
    "    # 8. МАСШТАБИРОВАНИЕ (сохраняем scaler)\n",
    "    print(\"\\n8. Масштабирование признаков...\")\n",
    "    \n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    \n",
    "    numeric_cols_to_scale = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    if numeric_cols_to_scale:\n",
    "        scaler = RobustScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train[numeric_cols_to_scale])\n",
    "        X_test_scaled = scaler.transform(X_test[numeric_cols_to_scale])\n",
    "        \n",
    "        X_train[numeric_cols_to_scale] = X_train_scaled\n",
    "        X_test[numeric_cols_to_scale] = X_test_scaled\n",
    "        \n",
    "        print(f\"✓ Масштабировано {len(numeric_cols_to_scale)} числовых признаков\")\n",
    "    else:\n",
    "        print(\"⚠ Нет числовых признаков для масштабирования\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ПРЕДОБРАБОТКА ЗАВЕРШЕНА!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Итоговые размеры:\")\n",
    "    print(f\"  X_train: {X_train.shape}\")\n",
    "    print(f\"  X_test:  {X_test.shape}\")\n",
    "    print(f\"  y_train: {y.shape if y is not None else 'None'}\")\n",
    "    \n",
    "    if y is not None:\n",
    "        print(f\"  Баланс классов: 0={100*(y==0).mean():.1f}%, 1={100*(y==1).mean():.1f}%\")\n",
    "    \n",
    "    return X_train, X_test, y, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1311932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружены данные: train=(1210779, 109), test=(134531, 108)\n",
      "============================================================\n",
      "НАЧАЛО ПРЕДОБРАБОТКИ (С СОХРАНЕНИЕМ ПАРАМЕТРОВ)\n",
      "============================================================\n",
      "Начальные размеры: train=(1210779, 109), test=(134531, 108)\n",
      "\n",
      "1. Удаление бесполезных признаков...\n",
      "✓ Удалено 7 признаков\n",
      "\n",
      "2. Обработка признаков...\n",
      "✓ Создан признак: стаж_кредитной_истории_мес\n",
      "✓ Создан признак: срок_займа_мес\n",
      "✓ Закодирован рейтинг\n",
      "✓ Закодирован стаж\n",
      "✓ Закодирован пос_стоп_фактор\n",
      "✓ Закодирован юридический_статус\n",
      "✓ One-hot: владение_жильем (6 категорий)\n",
      "✓ One-hot: подтвержден_ли_доход (3 категорий)\n",
      "✓ One-hot: первоначальный_статус_займа (2 категорий)\n",
      "✓ One-hot: тип_займа (2 категорий)\n",
      "✓ One-hot: тип_предоставления_кредита (2 категорий)\n",
      "✓ Frequency encoding: профессия_заемщика\n",
      "✓ Frequency encoding: допрейтинг\n",
      "✓ Frequency encoding: регион\n",
      "✓ Обработана цель_займа\n",
      "✓ Обработано пени_за_дефолт\n",
      "\n",
      "3. Создание новых признаков...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamshchikov/ML_practice/Torchvision_core_project/MLvenv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Создан: аннуитет_к_доходу\n",
      "✓ Создан: пдн_от_дохода\n",
      "✓ Создан: заем_к_доходу\n",
      "\n",
      "4. Обработка пропусков...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamshchikov/ML_practice/Torchvision_core_project/MLvenv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Заполнены пропуски в 63 числовых признаках\n",
      "\n",
      "5. Подготовка финальных наборов данных...\n",
      "\n",
      "6. Удаление константных признаков...\n",
      "✓ Удалено 3 константных признаков\n",
      "\n",
      "7. Выравнивание колонок...\n",
      "\n",
      "8. Масштабирование признаков...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamshchikov/ML_practice/Torchvision_core_project/MLvenv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return fnb._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "/home/yamshchikov/ML_practice/Torchvision_core_project/MLvenv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Масштабировано 94 числовых признаков\n",
      "\n",
      "============================================================\n",
      "ПРЕДОБРАБОТКА ЗАВЕРШЕНА!\n",
      "============================================================\n",
      "Итоговые размеры:\n",
      "  X_train: (1210779, 119)\n",
      "  X_test:  (134531, 119)\n",
      "  y_train: (1210779,)\n",
      "  Баланс классов: 0=80.0%, 1=20.0%\n",
      "\n",
      "Разделение на train/val:\n",
      "  X_train_split: (968623, 119)\n",
      "  X_val_split:   (242156, 119)\n",
      "  y_train_split: (968623,)\n",
      "  y_val_split:   (242156,)\n",
      "\n",
      "Обучение LightGBM...\n",
      "[100]\tvalid_0's auc: 0.752749\n",
      "[200]\tvalid_0's auc: 0.757696\n",
      "[300]\tvalid_0's auc: 0.760124\n",
      "[400]\tvalid_0's auc: 0.761504\n",
      "[500]\tvalid_0's auc: 0.762164\n",
      "\n",
      "Val AUC: 0.7622\n",
      "\n",
      "Переобучение на всех train данных...\n",
      "Финальная модель обучена на 1210779 записях\n",
      "\n",
      "Статистика предсказаний на тесте:\n",
      "  Min:  0.006307\n",
      "  Max:  0.960932\n",
      "  Mean: 0.198954\n",
      "  Std:  0.156196\n",
      "\n",
      "Статистика предсказаний на train:\n",
      "  Min:  0.004281\n",
      "  Max:  0.964006\n",
      "  Mean: 0.199621\n",
      "  Std:  0.156155\n",
      "\n",
      "============================================================\n",
      "ФИНАЛЬНЫЙ САБМИТ\n",
      "============================================================\n",
      "Размер: (134531, 2)\n",
      "Первые 10 строк:\n",
      "      ID    Proba\n",
      "85540387 0.069873\n",
      "28112500 0.046644\n",
      "65731570 0.103155\n",
      "65874747 0.532245\n",
      "57893355 0.309357\n",
      "80589347 0.351040\n",
      "36381174 0.098162\n",
      "  624831 0.250153\n",
      "44065675 0.255528\n",
      "  771518 0.342332\n",
      "\n",
      "✅ Сабмит сохранен: correct_final_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Загружаем данные\n",
    "train = pd.read_csv('../data/shift_ml_2026_train.csv', low_memory=False)\n",
    "test = pd.read_csv('../data/shift_ml_2026_test.csv', low_memory=False)\n",
    "\n",
    "print(f\"Загружены данные: train={train.shape}, test={test.shape}\")\n",
    "\n",
    "# Применяем исправленную предобработку\n",
    "X_train, X_test, y_train, test_ids = advanced_preprocessing_improved_fixed(\n",
    "    train, test, target_col='итоговый_статус_займа', RANDOM_STATE=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Разделяем на train/val\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=RANDOM_STATE, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"\\nРазделение на train/val:\")\n",
    "print(f\"  X_train_split: {X_train_split.shape}\")\n",
    "print(f\"  X_val_split:   {X_val_split.shape}\")\n",
    "print(f\"  y_train_split: {y_train_split.shape}\")\n",
    "print(f\"  y_val_split:   {y_val_split.shape}\")\n",
    "\n",
    "# Обучаем модель\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 31,\n",
    "    'min_child_samples': 20,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "print(\"\\nОбучение LightGBM...\")\n",
    "lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
    "lgb_model.fit(\n",
    "    X_train_split, y_train_split,\n",
    "    eval_set=[(X_val_split, y_val_split)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50, verbose=False),\n",
    "        lgb.log_evaluation(period=100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Оценка на val\n",
    "val_predictions = lgb_model.predict_proba(X_val_split)[:, 1]\n",
    "val_auc = roc_auc_score(y_val_split, val_predictions)\n",
    "print(f\"\\nVal AUC: {val_auc:.4f}\")\n",
    "\n",
    "# Переобучение на всех данных\n",
    "print(\"\\nПереобучение на всех train данных...\")\n",
    "final_model = lgb.LGBMClassifier(**lgb_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "print(f\"Финальная модель обучена на {len(X_train)} записях\")\n",
    "\n",
    "# Предсказания на тесте\n",
    "test_predictions = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"\\nСтатистика предсказаний на тесте:\")\n",
    "print(f\"  Min:  {test_predictions.min():.6f}\")\n",
    "print(f\"  Max:  {test_predictions.max():.6f}\")\n",
    "print(f\"  Mean: {test_predictions.mean():.6f}\")\n",
    "print(f\"  Std:  {test_predictions.std():.6f}\")\n",
    "\n",
    "# Для сравнения - предсказания на train\n",
    "train_predictions = final_model.predict_proba(X_train)[:, 1]\n",
    "print(f\"\\nСтатистика предсказаний на train:\")\n",
    "print(f\"  Min:  {train_predictions.min():.6f}\")\n",
    "print(f\"  Max:  {train_predictions.max():.6f}\")\n",
    "print(f\"  Mean: {train_predictions.mean():.6f}\")\n",
    "print(f\"  Std:  {train_predictions.std():.6f}\")\n",
    "\n",
    "# Создаем сабмит\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'Proba': test_predictions\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ФИНАЛЬНЫЙ САБМИТ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Размер: {submission.shape}\")\n",
    "print(f\"Первые 10 строк:\")\n",
    "print(submission.head(10).to_string(index=False))\n",
    "\n",
    "# Проверка на NaN\n",
    "if submission['Proba'].isna().any():\n",
    "    nan_count = submission['Proba'].isna().sum()\n",
    "    print(f\"\\n⚠ ВНИМАНИЕ: Найдено {nan_count} NaN значений!\")\n",
    "    mean_val = submission['Proba'].mean()\n",
    "    submission['Proba'] = submission['Proba'].fillna(mean_val)\n",
    "    print(f\"Заполнено средним значением: {mean_val:.6f}\")\n",
    "\n",
    "# Сохраняем\n",
    "submission.to_csv('correct_final_submission.csv', index=False)\n",
    "print(f\"\\n✅ Сабмит сохранен: correct_final_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e6fcddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.7599 (+/- 0.0006)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Кросс-валидация\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(\n",
    "    lgb_model, X_train_split, y_train_split,\n",
    "    cv=cv, scoring='roc_auc', n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"CV AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
